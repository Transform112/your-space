{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.9041769041769046,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09828009828009827,
      "grad_norm": 45.20686721801758,
      "learning_rate": 0.00018,
      "loss": 3.2969,
      "step": 10
    },
    {
      "epoch": 0.19656019656019655,
      "grad_norm": 8.487692832946777,
      "learning_rate": 0.00019995921928281894,
      "loss": 1.7554,
      "step": 20
    },
    {
      "epoch": 0.29484029484029484,
      "grad_norm": 8.063132286071777,
      "learning_rate": 0.00019981829160444514,
      "loss": 1.4505,
      "step": 30
    },
    {
      "epoch": 0.3931203931203931,
      "grad_norm": 7.214399814605713,
      "learning_rate": 0.00019957685536765995,
      "loss": 1.244,
      "step": 40
    },
    {
      "epoch": 0.4914004914004914,
      "grad_norm": 7.437548637390137,
      "learning_rate": 0.0001992351536782881,
      "loss": 1.2271,
      "step": 50
    },
    {
      "epoch": 0.5896805896805897,
      "grad_norm": 6.137208938598633,
      "learning_rate": 0.00019879353060096603,
      "loss": 1.1589,
      "step": 60
    },
    {
      "epoch": 0.687960687960688,
      "grad_norm": 6.332849502563477,
      "learning_rate": 0.00019825243081269774,
      "loss": 1.1893,
      "step": 70
    },
    {
      "epoch": 0.7862407862407862,
      "grad_norm": 6.845974922180176,
      "learning_rate": 0.00019761239915510302,
      "loss": 1.1351,
      "step": 80
    },
    {
      "epoch": 0.8845208845208845,
      "grad_norm": 6.635626792907715,
      "learning_rate": 0.00019687408008580784,
      "loss": 1.0864,
      "step": 90
    },
    {
      "epoch": 0.9828009828009828,
      "grad_norm": 5.986627101898193,
      "learning_rate": 0.00019603821702953046,
      "loss": 1.0835,
      "step": 100
    },
    {
      "epoch": 1.0786240786240786,
      "grad_norm": 6.523216247558594,
      "learning_rate": 0.00019510565162951537,
      "loss": 1.0112,
      "step": 110
    },
    {
      "epoch": 1.1769041769041768,
      "grad_norm": 6.486752510070801,
      "learning_rate": 0.00019407732290007023,
      "loss": 0.9399,
      "step": 120
    },
    {
      "epoch": 1.2751842751842752,
      "grad_norm": 6.581074237823486,
      "learning_rate": 0.00019295426628105792,
      "loss": 0.9329,
      "step": 130
    },
    {
      "epoch": 1.3734643734643734,
      "grad_norm": 6.826773166656494,
      "learning_rate": 0.00019173761259529633,
      "loss": 0.9508,
      "step": 140
    },
    {
      "epoch": 1.4717444717444716,
      "grad_norm": 6.472663879394531,
      "learning_rate": 0.00019042858690991574,
      "loss": 0.9556,
      "step": 150
    },
    {
      "epoch": 1.57002457002457,
      "grad_norm": 6.575468063354492,
      "learning_rate": 0.00018902850730281992,
      "loss": 0.9595,
      "step": 160
    },
    {
      "epoch": 1.6683046683046683,
      "grad_norm": 7.6202826499938965,
      "learning_rate": 0.00018753878353549357,
      "loss": 0.9051,
      "step": 170
    },
    {
      "epoch": 1.7665847665847667,
      "grad_norm": 6.663663864135742,
      "learning_rate": 0.00018596091563349192,
      "loss": 0.9608,
      "step": 180
    },
    {
      "epoch": 1.864864864864865,
      "grad_norm": 7.349499225616455,
      "learning_rate": 0.00018429649237604217,
      "loss": 0.9262,
      "step": 190
    },
    {
      "epoch": 1.9631449631449631,
      "grad_norm": 6.9224114418029785,
      "learning_rate": 0.0001825471896962774,
      "loss": 0.9422,
      "step": 200
    },
    {
      "epoch": 2.058968058968059,
      "grad_norm": 6.263022422790527,
      "learning_rate": 0.00018071476899371414,
      "loss": 0.8094,
      "step": 210
    },
    {
      "epoch": 2.157248157248157,
      "grad_norm": 8.898387908935547,
      "learning_rate": 0.00017880107536067218,
      "loss": 0.7518,
      "step": 220
    },
    {
      "epoch": 2.2555282555282554,
      "grad_norm": 10.384270668029785,
      "learning_rate": 0.00017680803572442318,
      "loss": 0.8055,
      "step": 230
    },
    {
      "epoch": 2.3538083538083536,
      "grad_norm": 6.83204460144043,
      "learning_rate": 0.0001747376569069381,
      "loss": 0.8153,
      "step": 240
    },
    {
      "epoch": 2.4520884520884523,
      "grad_norm": 7.492844104766846,
      "learning_rate": 0.00017259202360418762,
      "loss": 0.8021,
      "step": 250
    },
    {
      "epoch": 2.5503685503685505,
      "grad_norm": 9.960766792297363,
      "learning_rate": 0.00017037329628703004,
      "loss": 0.7991,
      "step": 260
    },
    {
      "epoch": 2.6486486486486487,
      "grad_norm": 6.915140151977539,
      "learning_rate": 0.00016808370902580036,
      "loss": 0.7749,
      "step": 270
    },
    {
      "epoch": 2.746928746928747,
      "grad_norm": 7.532264232635498,
      "learning_rate": 0.00016572556724079056,
      "loss": 0.7692,
      "step": 280
    },
    {
      "epoch": 2.845208845208845,
      "grad_norm": 8.355978012084961,
      "learning_rate": 0.00016330124538088705,
      "loss": 0.7963,
      "step": 290
    },
    {
      "epoch": 2.9434889434889433,
      "grad_norm": 9.129166603088379,
      "learning_rate": 0.0001608131845327018,
      "loss": 0.8295,
      "step": 300
    },
    {
      "epoch": 3.039312039312039,
      "grad_norm": 7.344890117645264,
      "learning_rate": 0.00015826388996260503,
      "loss": 0.7342,
      "step": 310
    },
    {
      "epoch": 3.1375921375921374,
      "grad_norm": 8.901280403137207,
      "learning_rate": 0.0001556559285941344,
      "loss": 0.6274,
      "step": 320
    },
    {
      "epoch": 3.235872235872236,
      "grad_norm": 8.629364967346191,
      "learning_rate": 0.0001529919264233205,
      "loss": 0.6594,
      "step": 330
    },
    {
      "epoch": 3.3341523341523343,
      "grad_norm": 7.238920211791992,
      "learning_rate": 0.0001502745658745316,
      "loss": 0.6282,
      "step": 340
    },
    {
      "epoch": 3.4324324324324325,
      "grad_norm": 7.342770099639893,
      "learning_rate": 0.0001475065830994995,
      "loss": 0.6668,
      "step": 350
    },
    {
      "epoch": 3.5307125307125307,
      "grad_norm": 8.886783599853516,
      "learning_rate": 0.0001446907652222468,
      "loss": 0.6377,
      "step": 360
    },
    {
      "epoch": 3.628992628992629,
      "grad_norm": 8.572993278503418,
      "learning_rate": 0.00014182994753268927,
      "loss": 0.703,
      "step": 370
    },
    {
      "epoch": 3.7272727272727275,
      "grad_norm": 8.435903549194336,
      "learning_rate": 0.00013892701063173918,
      "loss": 0.6833,
      "step": 380
    },
    {
      "epoch": 3.8255528255528253,
      "grad_norm": 9.5535249710083,
      "learning_rate": 0.00013598487753078425,
      "loss": 0.6412,
      "step": 390
    },
    {
      "epoch": 3.923832923832924,
      "grad_norm": 8.747708320617676,
      "learning_rate": 0.00013300651070846333,
      "loss": 0.686,
      "step": 400
    },
    {
      "epoch": 4.019656019656019,
      "grad_norm": 7.084843635559082,
      "learning_rate": 0.00012999490912770107,
      "loss": 0.6258,
      "step": 410
    },
    {
      "epoch": 4.117936117936118,
      "grad_norm": 8.417520523071289,
      "learning_rate": 0.0001269531052160068,
      "loss": 0.5164,
      "step": 420
    },
    {
      "epoch": 4.216216216216216,
      "grad_norm": 10.281911849975586,
      "learning_rate": 0.0001238841618120769,
      "loss": 0.5721,
      "step": 430
    },
    {
      "epoch": 4.314496314496314,
      "grad_norm": 8.572307586669922,
      "learning_rate": 0.00012079116908177593,
      "loss": 0.5251,
      "step": 440
    },
    {
      "epoch": 4.412776412776413,
      "grad_norm": 9.077258110046387,
      "learning_rate": 0.00011767724140660157,
      "loss": 0.5363,
      "step": 450
    },
    {
      "epoch": 4.511056511056511,
      "grad_norm": 7.738473415374756,
      "learning_rate": 0.00011454551424776637,
      "loss": 0.5585,
      "step": 460
    },
    {
      "epoch": 4.6093366093366095,
      "grad_norm": 12.574627876281738,
      "learning_rate": 0.00011139914098905406,
      "loss": 0.5493,
      "step": 470
    },
    {
      "epoch": 4.707616707616707,
      "grad_norm": 9.76574993133545,
      "learning_rate": 0.00010824128976162964,
      "loss": 0.5491,
      "step": 480
    },
    {
      "epoch": 4.805896805896806,
      "grad_norm": 8.8334321975708,
      "learning_rate": 0.00010507514025399943,
      "loss": 0.554,
      "step": 490
    },
    {
      "epoch": 4.9041769041769046,
      "grad_norm": 10.919758796691895,
      "learning_rate": 0.00010190388051033466,
      "loss": 0.5426,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 329057361120000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
